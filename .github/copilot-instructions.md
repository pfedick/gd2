# AI Coding Guide for gd2 / PPL7 / PPLTK

## General AI Assistant Guidelines

**Code generation philosophy**: Avoid generating large blocks of code the user doesn't understand. Instead:
- Explain concepts and patterns step-by-step
- Provide focused code snippets (minimal examples, not full implementations)
- Guide the user through problem-solving: ask clarifying questions, suggest approaches, let them write/adapt code
- Reference existing files/patterns in the codebase to learn from
- Prioritize teaching over fast delivery (Learning by Doing)

**When asked to implement features**:
- Start with architecture/design discussion
- Show a minimal skeleton or example
- Explain the "why" behind choices
- Let the user fill in details and adapt to their needs
- Review and refactor together, not in isolation

## Project Overview
gd2 is a **2D Jump'n'Run game** using SDL3 GPU API for advanced rendering (normal maps, parallax scrolling, per-layer blur). See [DeckerGame](https://github.com/pfedick/DeckerGame) (SDL2, Windows-only) as the spiritual predecessor; this rewrite targets **Windows (mingw64/msys), Linux, and FreeBSD** and leverages SDL3's new GPU features.

## Build & Dependencies
- Repo layout: root autotools project stitches Patrick's Programming Library (PPL7, static libs under `pplib/release`) and the GUI toolkit (PPLTK, static lib under `ppltk/compile`); top-level `Makefile` links them into the `gd2` app.
- Bootstrap/build: run `./genConfigure` then `./configure` (C++23 enforced) at repo root to generate Makefiles, then `make ppl7`, `make ppl_toolkit`, `make gd2`; `make mingw` builds a Windows deploy folder and Inno Setup script; `make cleanall` also cleans libs. In subprojects you can `cd pplib` or `cd ppltk` and run their own `genConfigure`/`configure`/`make` flows when working locally.
- Hard deps checked in [configure.ac](configure.ac): zlib, bzip2, pcre2, iconv, libpng, libjpeg/libjpeg-turbo, freetype2, SDL3, mpg123, libvorbis, dav1d, assimp; configure aborts if any are missing. Optional extras in PPL7 configure (OpenSSL, DBs, curl, etc.) are picked up via pkg-config and `--with/--without` flags.
- PPL7 library makeup (see targets in [pplib/Makefile.in](pplib/Makefile.in)): `core` (filesystem, threading, JSON, resources), `types` (String/Array/Variant), `crypto`, `inet` (sockets, TLS, curl), `db` (MySQL/PostgreSQL/SQLite), `grafix` (images, fonts, sprite blitting), `audio` (decoders/encoders, ID3). Release libs land in `pplib/release`; debug/coverage object trees also exist for tests.
- PPL7 tests (gtest) live in [pplib/tests](pplib/tests): run `cd pplib && ./genConfigure && ./configure && make -j && cd tests && make test` to build `test_core`, `test_crypto`, `test_database`, `test_audio`, `test_grafix`, `test_inet`; `make xml` emits junit XML; `make coverage` links with gcov flags. Tests rely on `../ppl7-config` (generated by configure) and expect the debug libs to be built.
- PPLTK build (see [ppltk/Makefile.in](ppltk/Makefile.in)): builds `compile/libppltk.a` plus demo app; uses `-Dmain=SDL_main` and links SDL3 + PPL7. `make fonts` regenerates `.fnt6` bitmap fonts from system Liberation fonts; `make res` packs `resources/` into `resources/res.h` via `pplgenresource`.
- PPLTK architecture highlights:
  - Singleton window manager: [ppltk/src/WindowManager.cpp](ppltk/src/WindowManager.cpp) keeps a single global `WindowManager` (`wm`), accessed via `GetWindowManager()`/`GetWidgetStyle()`. Instantiate exactly once; destructor clears the global.
  - Styling/resources: constructor loads default and mono fonts plus toolbar icons from `GetPPLTKResource()`; button symbols recolored per `WidgetStyle` in `updateButtonSymbols()`.
  - Event dispatch: `dispatchMouseEvent` routes events to the deepest child hit (`findMouseWidget` walks children back-to-front, respecting modal widgets and an optional grab) and maintains focus trackers (`LastMouseDown/Enter/Focus`, `grabMouseWidget`); double-click detection uses `clickCount` and a delayed `startClickEvent`.
  - Widgets as a tree ([ppltk/src/Widget.cpp](ppltk/src/Widget.cpp)): manage parent/child lists, optional layout, and redraw flags. `needsRedraw`/`childNeedsRedraw` propagate up the tree; `destroyChilds`/`deleteLater` support deferred deletion used by the manager. Geometry/state changes should call `geometryChanged`/`invalidateLayout`; `setUseOwnDrawbuffer` allocates a per-widget buffer when needed.
- SDL integration: input/key codes and controllers flow through `Event` subclasses in [ppltk/src/Event.cpp](ppltk/src/Event.cpp), so new widgets override the specific event handlers rather than polling SDL directly.
- Resources/fonts: font names referenced in code assume the generated `.fnt6` files; if you change fonts, regenerate and commit both the font files and `resources/res.h` to keep runtime loads working.
- Coding conventions: prefer existing PPL7 types (`ppl7::String`, `ppl7::grafix::ImageList`, etc.) and exception macros (`PPL7EXCEPTION`); respect the redraw/focus lifecycle managed by `WindowManager` instead of manually painting outside the tree.
- Release packaging: `make mingw` copies dependent ucrt64 DLLs next to `gd2.exe` and rewrites `setup.iss`; `make setup` runs Inno Setup to produce an installer.
## SDL3 GPU Architecture

**Renderer vs GPU path**: For gd2, **use SDL3's GPU API** (not SDL_Renderer) for all drawable sprites, tiles, and lighting passes. Mix SDL_Renderer with GPU in the same frame is awkward; commit to GPU-first: `SDL_CreateGPUDevice()` → command buffers → pipelines, bind groups, GPU textures.

**Texture loading workflow**:
- Load image files via `SDL_LoadBMP` or `IMG_Load` into CPU pixels.
- Create GPU textures: `SDL_CreateGPUTexture()` with `SDL_TEXTUREUSAGE_SAMPLING`.
- Upload via `SDL_UploadToGPUTexture()`.
- Offscreen render targets (e.g., for blur passes) use `SDL_TEXTUREUSAGE_RENDERTARGET`.
- Keep CPU copies only for streaming/dynamic updates.

**Minimal frame loop**:
```cpp
auto cmd = SDL_AcquireGPUCommandBuffer(device);
auto pass = SDL_BeginRenderPass(cmd, &renderPassDesc);
SDL_BindGPUGraphicsPipeline(pass, pipeline);
SDL_BindGPUVertexBuffers(pass, ...);
SDL_BindGPUFragmentSamplers(pass, ...);  // textures/samplers
SDL_DrawPrimitives(pass, vertexCount);
SDL_EndRenderPass(pass);
// Optionally: blur pass on offscreen texture
SDL_SubmitGPUCommandBuffer(cmd);
SDL_PresentGPUWindow(window);
```

## Lighting & Normal Mapping

**Asset structure**: Each sprite/tile holds albedo (RGB) and normal map (RG with Y-up convention or packed XY). Optionally store roughness/emissive in a third channel or separate texture.

**Shader approach**:
- Vertex: output world/tangent-space basis, UV, layer depth.
- Fragment: sample albedo + normal map; apply per-light loop (start with 1–2 point lights + ambient).
- Uniforms: view/projection matrices, light positions/colors, camera position (for specular).
- Return lit color = albedo × (ambient + Σ(diffuse + specular)).

**Performance**: Use instancing or single large vertex buffer per layer. Avoid per-sprite pipeline switches; batch by bind group (texture sets).

## Parallax Scrolling & Depth Blur

**Parallax layers**: Store each layer with a parallax factor (0.0 = fixed, 1.0 = camera depth). Offset layer's camera position by `camera.offset * parallax_factor` during rendering.

**Depth blur**:
1. Render far layers to offscreen color target (half-res to save bandwidth).
2. Apply separable Gaussian blur (horizontal pass → intermediate, vertical pass → final blur texture).
3. Composite blurred far layers + sharp near layers to main render target.
4. Use small kernels (5–9 tap) for performance; profile on target GPUs.

### Parallax Size Scaling (per-layer 1:1 on player layer)

- Goal: Keep sprites 1:1 on the main player layer; render smaller on far layers and larger on near layers.
- Data: add to each visual layer:
  - `parallax_factor` (scroll offset multiplier)
  - `scale` (size multiplier; 1.0 for player layer; <1.0 for far; >1.0 for near)
  - Optional `depth` to derive `scale` via a mapping.
- Suggested mappings:
  - Direct: `scale = layer.scale` (author-defined)
  - Depth-based: `scale = 1.0 / (1.0 + k * depth)` or `scale = mix(near_scale, far_scale, depth_norm)`
- Rendering transform per layer: `M_layer = T(camera_offset * parallax_factor) * S(scale)`; apply `M_layer` before the per-entity transform.
- Collision decoupling: collision/tile sizes stay constant in the `CollisionGrid`; only rendering uses `scale`.
- Assets and filtering:
  - Generate mipmaps for albedo and normal maps to avoid shimmer when downscaling.
  - Use appropriate min/mag filters (linear for modern look; nearest for retro).
  - Ensure normal map uses the same sampler and LOD policy as albedo.
- UI is unscaled: render ppltk HUD after world with `scale = 1.0`.

## Shader & Resource Binding

- Create one shader pipeline for lit sprites; separate simple pipeline for UI/unlit HUD.
- Use sampler objects: wrap clamp for sprites, wrap repeat for tiled backgrounds.
- Bind albedo + normal texture per draw or per layer in a `bind group`; add per-draw uniform (sprite rect, animation frame) if needed.
- Additive blend mode for glow/emissive passes.

## Coordinate Systems

- Choose consistent origin (NDC with Y up is standard) and bake into vertex shader.
- Keep normals in tangent space for flexibility.
- Ensure UV origin matches texture load expectations (top-left vs bottom-left) to avoid flipped normals.

## Screen Resolution & Scaling

**Avoid fixed-resolution upscaling blur**: Fixed 1920×1080 → screen resolution causes blur on upscaling and pixelation on downscaling. Instead:

**Recommended: Render at actual screen resolution**
- Render game viewport directly at window size; adjust camera/viewport per resolution.
- Use viewport clipping and scissor rects (available in GPU API) to letterbox/pillarbox if you need fixed aspect ratio.
- Performance varies with resolution, but modern GPUs handle this well.

**Alternative: Integer scaling with fixed internal resolution**
- Render at fixed 1920×1080 (or smaller), then upscale by integer multiples (2×, 3×, etc.) using nearest-neighbor sampling (no filtering).
- Only works cleanly on screen sizes that are exact multiples of your internal res.
- Gives crisp pixel-perfect output for retro/sprite-based games.
- Use a simple fullscreen blit with `SDL_SAMPLERCLAMPTO_EDGE` and no filtering; or write a trivial upscaling quad shader.

**For this project**: Recommend rendering at screen resolution (let viewport/projection matrix handle scaling). Use `SDL_GetWindowSizeInPixels()` to get actual rendering size, build projection matrix accordingly, and update on window resize events. Parallax layers naturally adapt since they're offset in world space.

**Avoid**: 4K → lower res downscaling is overkill; introduces overhead and diminishing returns unless targeting specific high-DPI displays.

## Asset Resolution Strategy

When rendering at screen resolution, sprite quality depends on asset resolution:

**High-res sprites (recommended)**
- Create sprites at or above your target base resolution (e.g., 1920×1080 minimum, or 2× for future-proofing). Hand-draw/paint at this scale to avoid quality loss.
- At runtime, GPU sampling (linear filter) scales cleanly to any window size. Upscaling 1080p → 4K is acceptable; downscaling is always better quality.
- Parallax layers scale transparently since offsets are in world space.

**Adaptive asset loading** (complex)
- Load different sprite sheets per detected DPI or resolution bucket (e.g., 1080p set for 1080–1440p, 2K set for 1440–2160p).
- Ensures sprites always sharp but requires managing multiple asset sets; practical only for very high-end productions.

**Avoid**: Creating sprites at 1920×1080 fixed, then upscaling beyond that window size → blurry. Either create assets larger from the start or stick to integer-scale windows (if using nearest-neighbor).

## Migration Notes from SDL2 / DeckerGame

- `SDL_Texture` (renderer) → `SDL_GPUTexture` (explicit GPU resource). No implicit blits; issue draw calls with bound data.
- Shaders are **explicit pipelines** from compiled bytecode (SPIR-V/DXIL/MSL depending on backend). Compile GLSL/HLSL offline or use SDL_shader helpers at runtime.
- Render targets are explicit: offscreen blur requires `SDL_GPUTexture` with `SDL_TEXTUREUSAGE_RENDERTARGET`.
- No `SDL_RenderCopyEx` or automatic scaling; write your own quad drawing with viewport/scissor if needed.

## pplib/ppltk Integration

- ppltk window/event loop already migrated to SDL3; ensure GPU device creation uses the ppltk window handle.
- Use pplib for string utilities, file I/O (asset loading), and the `grafix` namespace for CPU-side pixel manipulation if needed (e.g., generating height/normal maps on load).
- Keep ppltk UI separate from game GPU rendering: ppltk for menus, game loop for parallax/lighting.
## Audio Mixing & SDL3

**Architecture**:
- Maintain separate mix channels: music, sound effects, voice (or UI). Float-based mixing (32-bit) is cleaner than integer and reduces rounding artifacts in multi-channel blend.
- pplib provides audio decoders/encoders (MP3, Ogg, AIFF, Wave via `ppl7::audio` namespace) and ID3 tag reading; use these to load source files.

**SDL3 audio vs SDL2**:
- SDL2: audio callback with fixed format push/pull. SDL3: audio streams API is more flexible; create streams per logical channel or one stream per source, then mix in software before final device output.
- No more audio format conversion awkwardness; SDL3 handles resampling better.
- Consider using `SDL_OpenAudioDeviceStream()` for device output and `SDL_CreateAudioStream()` for source mixing pipelines.

**Float mixing strategy**:
- Load source (e.g., Ogg via pplib decoder) → resample to target rate (e.g., 48 kHz) → mix channels as float (accumulate with pan/volume per channel) → clamp to [-1.0, 1.0] → convert to output format (S16 or float depending on device).
- Keep accumulated samples as float to minimize precision loss; convert to S16/S32 only at device output if hardware is integer.
- Separate channel volumes and pans; sum all channels in a single mix pass per frame.

**Practical setup**:
- Create one output stream to the audio device (stereo, float or S16).
- Maintain ring buffers or streaming sources for music (with loop points), SFX (fire-and-forget), voice (streaming or queued).
- Each frame (or per audio callback if using one), read from sources, apply gain/pan per channel, sum, and submit to output stream.

**Performance**:
- Float mixing is CPU-cheap on modern hardware. Profile on target platforms (Windows mingw, Linux).
- Resample once at load time if possible, or use fast linear/cubic resampling per-frame.
- Consider limiting voice channels (e.g., max 4 simultaneous voices) to reduce CPU.

## World Architecture: Data & Draw Order

- Core model: keep one canonical grid for gameplay/collision and separate visual layers for rendering.
  - `CollisionGrid` (fixed raster): per-cell flags/types (solid, slope, ladder, ramp, platform, hazard). Not rendered; used by physics.
  - `TileLayers[]` (visual): 2–4 layers of tilemaps that reference atlas frames (albedo + normal). Each layer has `parallax_factor` and optional blur participation.
  - `Entities[]`: free-placed sprites/objects with components: Transform (x,y,z), Render (atlas frame/albedo+normal), Collider (optional), Interaction (optional).
  - `Lights[]`: point/ambient lights with position, color, radius, intensity; optionally associated to a render layer.

- Storage format (binary, chunk-based): reuse your DeckerGame-style chunk I/O.
  - File = sequence of chunks: `[CHDR|PAYLOAD]*` with alignment (e.g., 4–16 bytes).
  - `CHDR` fields: `tag` (FourCC), `version` (u16/u32), `size` (u32 payload bytes), optional `flags`.
  - Suggested tags: `META` (level meta), `TILE` (tile layers), `COLL` (collision grid), `ENTS` (entities), `LGHT` (lights), `PARA` (parallax), `ATLS` (atlas refs).
  - Endianness: little-endian across platforms; validate with a magic header.
  - Compatibility: unknown chunks are skipped via `size` seek; version per-chunk enables selective migration.
  - Compression (optional): allow `flags` to mark zlib-compressed payload; decode after read.
  - Implementation: use PPL7 `File`, `ByteArray`, `String` for I/O; each data class exposes `writeChunk(File&)` / `readChunk(File&, CHDR)`.

- Render ordering (per frame):
  1) Background parallax layers → offscreen target (optional downsample) → blur passes
  2) Mid/foreground tile layers (sharp) → main target
  3) Entities behind tiles (z < layer mid)
  4) Player and interactables
  5) Foreground entities and overlay tiles
  6) UI/HUD via ppltk (unlit pipeline)

- Batching strategy:
  - Group tiles/entities by atlas/material to minimize pipeline/bind switches.
  - Build per-layer render lists; sort by texture, then draw.
  - Use instancing for repeated tiles; push small per-draw uniforms (UV rect, transform).

- Parallax & blur:
  - Each visual layer carries `parallax_factor` (0.0 fixed → 1.0 camera). Far layers render to half-res offscreen and run separable Gaussian blur before compositing.

- Keep it simple:
  - One physics grid → less confusion; visuals decoupled from collision.
  - Entities carry `render_layer` and `z` for front/behind placement instead of duplicating structures per layer.

## Roadmap: Next Steps (execution order)

- Basic game loop + UI: create a minimal loop with ppltk-managed window, event pump, and a simple top menu bar (pause, options, quit). Keep UI on a separate unlit pipeline.
- World building blocks: design core tiles/props in Lightwave 3D, render sprite sheets; define per-asset albedo + normal (and optional gloss/emissive) outputs.
- Player character: design and render the hero sprite set (idle/run/jump/land), with matching normal maps.
- Level data model: define data objects and serialization for worlds/levels (tiles, entities, layers, parallax factors, light sources). Target a human-editable format first (e.g., ppl7::AssocArray/JSON) and evolve to a packed binary if needed.
- In-UI editor: integrate a simple level editor in ppltk (tile palette, layer panel, painting tools, save/load), leveraging widget tree and redraw lifecycle.
- Asset loading: implement loaders for pre-rendered sprites with normal maps (and optional highlights), build GPU textures and samplers, batch by atlas when possible.
- Character rendering + movement: render the hero, add basic movement/animation state machine; verify input mapping via ppltk events.
- Lighting: add a lit sprite pipeline (albedo + normal), start with ambient + 1–2 point lights; expose uniforms for light color/position.
- Parallax: add multiple layers with per-layer parallax factors; order draw calls back-to-front.
- Depth blur: render distant layers to an offscreen target and apply separable Gaussian blur (small kernel), then composite with sharp near layers.

Notes
- Assets are authored in Lightwave 3D, then imported as 2D sprites with normal maps.
- Keep renderer GPU-first; avoid mixing SDL_Renderer with GPU API in a frame.
- Favor small, focused changes and “Learning by Doing” over large code drops.

